#!/usr/bin/env python3
"""
MLB Predictor v2.1 - Historical Data Pull
Pull 2023-2025 Statcast data + weather for ML training.
"""
import pandas as pd
from pybaseball import statcast
from datetime import datetime
import time

print("="*80)
print("MLB PREDICTOR v2.1 - HISTORICAL DATA PULL")
print("="*80)
print(f"Start time: {datetime.now()}")
print()

# Define seasons
seasons = [
    ('2023', '2023-04-01', '2023-10-31'),
    ('2024', '2024-04-01', '2024-10-31'),
    ('2025', '2025-04-01', '2025-10-31')
]

all_data = []

for season_name, start_date, end_date in seasons:
    print(f"ğŸ“¥ Pulling {season_name} season ({start_date} to {end_date})...")
    start_time = time.time()
    
    try:
        df = statcast(start_date, end_date)
        elapsed = time.time() - start_time
        
        print(f"   âœ… {season_name}: {len(df):,} rows in {elapsed:.1f}s")
        print(f"   ğŸ“Š Columns: {len(df.columns)}")
        print(f"   ğŸ’¾ Memory: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
        
        # Add season label
        df['season'] = season_name
        all_data.append(df)
        
        # Rate limit (be nice to MLB servers)
        if season_name != seasons[-1][0]:
            print(f"   â³ Waiting 5 seconds before next pull...")
            time.sleep(5)
        
    except Exception as e:
        print(f"   âŒ Error pulling {season_name}: {e}")
        continue

if all_data:
    print()
    print("="*80)
    print("COMBINING SEASONS")
    print("="*80)
    
    combined_df = pd.concat(all_data, ignore_index=True)
    
    print(f"âœ… Total rows: {len(combined_df):,}")
    print(f"âœ… Total columns: {len(combined_df.columns)}")
    print(f"âœ… Date range: {combined_df['game_date'].min()} to {combined_df['game_date'].max()}")
    print(f"âœ… Unique batters: {combined_df['batter'].nunique():,}")
    print(f"âœ… Unique pitchers: {combined_df['pitcher'].nunique():,}")
    print(f"âœ… Memory usage: {combined_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    
    # Save to parquet (compressed)
    output_file = 'statcast_2023_2025_RAW.parquet'
    print()
    print(f"ğŸ’¾ Saving to {output_file}...")
    combined_df.to_parquet(output_file, compression='snappy', index=False)
    
    file_size_mb = pd.io.common.get_filepath_or_buffer(output_file)[0]
    import os
    file_size_mb = os.path.getsize(output_file) / 1024**2
    
    print(f"âœ… Saved! File size: {file_size_mb:.1f} MB")
    
    print()
    print("="*80)
    print("SAMPLE DATA (First Row)")
    print("="*80)
    print(combined_df.iloc[0])
    
    print()
    print(f"End time: {datetime.now()}")
    print("ğŸ‰ DATA PULL COMPLETE!")

else:
    print("âŒ No data pulled. Check errors above.")

